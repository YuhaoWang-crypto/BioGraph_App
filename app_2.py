import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
import re
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
# è¿™é‡Œçš„ CountVectorizer å¦‚æœæ²¡ç”¨åˆ°å¯ä»¥å»æ‰ï¼Œå‡å°å†…å­˜å ç”¨

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(
    page_title="BioGraph: Protein Lifecycle Explorer",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ§¬ BioGraph: å¤šç»´è›‹ç™½è´¨ç»„å­¦æµå½¢åˆ†æå¹³å°")
st.markdown("""
**çœŸå®æ•°æ®é©±åŠ¨**ï¼šæœ¬å¹³å°å±•ç¤ºäº†åŸºäº UniProt çœŸå®åºåˆ—ä¸æ¨¡æ‹Ÿç»„å­¦æ•°æ®çš„æ·±åº¦åˆ†æç»“æœã€‚
å·²é¢„å…ˆé›†æˆäº† UMAP æµå½¢æŠ•å½±ã€K-Means èšç±»åŠåŠŸèƒ½å¯Œé›†åˆ†æã€‚
""")

# ==========================================
# 2. æ•°æ®åŠ è½½ (è¯»å– GZ å‹ç¼©æ–‡ä»¶)
# ==========================================
@st.cache_data
def load_data():
    """
    è¯»å–å‹ç¼©çš„ CSV æ–‡ä»¶ (.csv.gz)ã€‚
    Pandas ä¼šæ ¹æ®æ–‡ä»¶åç¼€è‡ªåŠ¨æ¨æ–­è§£å‹æ–¹å¼ï¼Œæˆ–è€…æ˜¾å¼æŒ‡å®š compression='gzip'ã€‚
    """
    try:
        # === ä¿®æ”¹ç‚¹ï¼šè¯»å– .csv.gz æ–‡ä»¶ ===
        # Pandas èƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ« .gz åç¼€å¹¶è§£å‹
        df = pd.read_csv("final_analysis_result.csv.gz", compression='gzip')
        
        # --- ä¸‹é¢æ˜¯å¸¸è§„æ¸…æ´—é€»è¾‘ ---
        
        # ç®€å•çš„æ¸…æ´—ï¼Œé˜²æ­¢ NaN æŠ¥é”™
        if 'cc_function' in df.columns:
            df['cc_function'] = df['cc_function'].fillna('Unknown')
        
        if 'Gene_Symbol' in df.columns:
            df['Gene_Symbol'] = df['Gene_Symbol'].fillna('Unknown')
        
        # ç¡®ä¿åŠè¡°æœŸæ•°å€¼æ­£å¸¸
        if 'Real_Protein_HalfLife_Hours' in df.columns:
            df['Real_Protein_HalfLife_Hours'] = df['Real_Protein_HalfLife_Hours'].fillna(0)
            
        # ç”Ÿæˆè¾…åŠ©æ ‡ç­¾
        if 'Real_Protein_HalfLife_Hours' in df.columns:
            df['Stability_Level'] = pd.cut(df['Real_Protein_HalfLife_Hours'], 
                                           bins=[-1, 10, 50, 10000], 
                                           labels=['Short (<10h)', 'Medium', 'Long (>50h)']).astype(str)
        
        return df
    except FileNotFoundError:
        st.error("âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼è¯·ç¡®ä¿ 'final_analysis_result.csv.gz' å·²ä¸Šä¼ åˆ°é¡¹ç›®æ ¹ç›®å½•ã€‚")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"âŒ æ•°æ®è¯»å–å‡ºé”™: {e}")
        return pd.DataFrame()

# åŠ è½½ä¸»æ•°æ®
df_main = load_data()

if df_main.empty:
    st.stop() # å¦‚æœæ²¡æ•°æ®ï¼Œåœæ­¢è¿è¡Œ

# ==========================================
# 3. å¿«é€Ÿé‡ç®— PCA Loadings (ä¸ºäº†ç”»ç®­å¤´å›¾)
# ==========================================
@st.cache_data
def calculate_pca_loadings(df):
    """
    å› ä¸º CSV é‡Œåªæœ‰åæ ‡æ²¡æœ‰æ¨¡å‹ï¼Œè¿™é‡Œå¿«é€Ÿé‡è·‘ä¸€æ¬¡ PCA ä»¥è·å–å› å­è½½è·ã€‚
    """
    # é€‰å–æ•°å€¼åˆ— (å¿…é¡»ä¸ Colab åˆ†ææ—¶ä¸€è‡´)
    features = ['Real_Protein_HalfLife_Hours', 'mRNA_Expression', 'Circadian_Amplitude']
    
    # ç¡®ä¿åˆ—å­˜åœ¨
    valid_features = [f for f in features if f in df.columns]
    
    if len(valid_features) < 2:
        return None, None
        
    # å–å¯¹æ•°å¹¶æ ‡å‡†åŒ–
    X = np.log1p(df[valid_features].fillna(0))
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    pca = PCA(n_components=2)
    pca.fit(X_scaled)
    
    loadings = pd.DataFrame(
        pca.components_.T, 
        columns=['PCA1', 'PCA2'], 
        index=valid_features
    )
    return loadings, valid_features

df_loadings, used_features = calculate_pca_loadings(df_main)

# ==========================================
# 4. ä¾§è¾¹æ ï¼šå…¨å±€è¿‡æ»¤å™¨
# ==========================================
st.sidebar.header("ğŸ” æ•°æ®ç­›é€‰")

# 1. Cluster ç­›é€‰
if 'Cluster' in df_main.columns:
    all_clusters = sorted(df_main['Cluster'].unique())
    selected_clusters = st.sidebar.multiselect(
        "ç­›é€‰ Cluster ID",
        options=all_clusters,
        default=all_clusters
    )
    # åº”ç”¨ç­›é€‰
    df_filtered = df_main[df_main['Cluster'].isin(selected_clusters)]
else:
    df_filtered = df_main

# 2. æœç´¢åŸºå› é«˜äº®
search_gene = st.sidebar.text_input("æœç´¢ç‰¹å®šåŸºå›  (å¦‚ TP53, ALB)", "").upper()

st.sidebar.markdown("---")
st.sidebar.info(f"å½“å‰å±•ç¤º: {len(df_filtered)} / {len(df_main)} ä¸ªè›‹ç™½")


# ==========================================
# 5. ä¸»ç•Œé¢ Tabs
# ==========================================
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸŒŒ å…¨æ™¯æµå½¢ (UMAP)", 
    "ğŸ” è›‹ç™½é›·è¾¾ (Search)", 
    "ğŸ•¸ï¸ åŠŸèƒ½ç½‘ç»œ (Network)", 
    "ğŸ“‰ PCA è§£å¯† (Loadings)",
    "ğŸ§ª ä¸“ä¸šå¯Œé›† (Heatmap)"
])

# --- Tab 1: UMAP å…¨æ™¯ ---
with tab1:
    col1, col2 = st.columns([1, 4])
    with col1:
        # åŠ¨æ€è·å–å¯ç”¨çš„ä¸Šè‰²é€‰é¡¹
        available_cols = [c for c in ['Cluster', 'Stability_Level', 'N_Term_AA', 'Is_Cancer'] if c in df_filtered.columns]
        # å¦‚æœ Is_Cancer è¿˜æ²¡è®¡ç®—ï¼Œä¸”æœ‰ cc_functionï¼Œåˆ™ç®—ä¸€ä¸‹
        if 'Is_Cancer' not in df_filtered.columns and 'cc_function' in df_filtered.columns:
             df_filtered['Is_Cancer'] = df_filtered['cc_function'].str.contains('cancer|tumor', case=False).map({True:'Yes', False:'No'})
             available_cols.append('Is_Cancer')
             
        color_col = st.radio("ä¸Šè‰²ä¾æ®:", available_cols, index=0)

    with col2:
        if 'UMAP_X' in df_filtered.columns:
            fig = px.scatter(
                df_filtered, 
                x='UMAP_X', y='UMAP_Y', 
                color=color_col,
                hover_data=['Gene_Symbol', 'Real_Protein_HalfLife_Hours', 'cc_function'],
                title=f"Functional Manifold (Colored by {color_col})",
                height=650,
                template="plotly_white",
                opacity=0.6,
                color_discrete_sequence=px.colors.qualitative.Bold
            )
            
            # æ ‡è®°æœç´¢çš„åŸºå› 
            if search_gene and not df_filtered[df_filtered['Gene_Symbol'] == search_gene].empty:
                row = df_filtered[df_filtered['Gene_Symbol'] == search_gene].iloc[0]
                fig.add_trace(go.Scatter(
                    x=[row['UMAP_X']], y=[row['UMAP_Y']],
                    mode='markers+text',
                    marker=dict(size=20, color='red', symbol='star', line=dict(width=2, color='black')),
                    text=[search_gene],
                    textposition="top center",
                    name='Searched'
                ))

            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("æ•°æ®ä¸­ç¼ºå°‘ UMAP åæ ‡åˆ—ï¼Œæ— æ³•ç»˜å›¾ã€‚")

# --- Tab 2: è¯¦æƒ…é›·è¾¾ ---
with tab2:
    gene_list = sorted(df_main['Gene_Symbol'].unique())
    default_idx = 0
    if search_gene and search_gene in gene_list:
        default_idx = gene_list.index(search_gene)
        
    selected_gene_tab2 = st.selectbox("é€‰æ‹©åŸºå› æŸ¥çœ‹è¯¦æƒ…:", gene_list, index=default_idx)
    
    if selected_gene_tab2:
        row = df_main[df_main['Gene_Symbol'] == selected_gene_tab2].iloc[0]
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.subheader(f"ğŸ§¬ {selected_gene_tab2}")
            st.write(f"**Nç«¯æ°¨åŸºé…¸:** {row.get('N_Term_AA', 'N/A')}")
            st.write(f"**å¤„ç†ç±»å‹:** {row.get('Processing_Type', 'N/A')}")
            st.metric("çœŸå®åŠè¡°æœŸ", f"{row.get('Real_Protein_HalfLife_Hours', 0):.1f} h")
            st.metric("mRNA è¡¨è¾¾é‡", f"{row.get('mRNA_Expression', 0):.2f}")
            st.info(f"æ‰€å± Cluster: {row.get('Cluster', 'N/A')}")
            
        with c2:
            st.markdown("### åŠŸèƒ½æè¿°")
            st.caption(row.get('cc_function', 'No description available.'))
            
            st.markdown("### åæ ‡ä¿¡æ¯")
            st.json({
                "UMAP": [round(row.get('UMAP_X', 0), 2), round(row.get('UMAP_Y', 0), 2)],
                "PCA": [round(row.get('PCA1', 0), 2), round(row.get('PCA2', 0), 2)]
            })

# --- Tab 3: ç½‘ç»œ (ç®€åŒ–ç‰ˆ) ---
with tab3:
    st.markdown("### åŠ¨æ€æ„å»ºåŠŸèƒ½æ¨¡å—ç½‘ç»œ")
    keyword = st.text_input("è¾“å…¥å…³é”®è¯:", "mitochondrial")
    
    if keyword:
        subset = df_main[df_main['cc_function'].str.contains(keyword, case=False, na=False)].head(150)
        
        if len(subset) > 1:
            G = nx.Graph()
            genes = subset['Gene_Symbol'].tolist()
            hls = subset['Real_Protein_HalfLife_Hours'].tolist()
            
            for i in range(len(genes)):
                G.add_node(genes[i])
                for j in range(i+1, len(genes)):
                    if abs(hls[i] - hls[j]) < 2.0:
                        G.add_edge(genes[i], genes[j])
            
            fig_net, ax = plt.subplots(figsize=(10, 8))
            pos = nx.spring_layout(G, k=0.15, seed=42)
            nx.draw_networkx_nodes(G, pos, node_size=30, node_color='teal', alpha=0.6, ax=ax)
            nx.draw_networkx_edges(G, pos, alpha=0.1, ax=ax)
            if len(genes) < 50: 
                nx.draw_networkx_labels(G, pos, font_size=8, ax=ax)
            
            ax.set_title(f"Network for '{keyword}' ({len(genes)} nodes)")
            ax.axis('off')
            st.pyplot(fig_net)
        else:
            st.warning("æ‰¾ä¸åˆ°è¶³å¤Ÿçš„ç›¸å…³è›‹ç™½ï¼Œè¯·æ›´æ¢å…³é”®è¯ã€‚")

# --- Tab 4: PCA Loadings ---
with tab4:
    if df_loadings is not None:
        col_l, col_r = st.columns(2)
        with col_l:
            st.write("### å› å­è½½è·è¡¨")
            st.dataframe(df_loadings.style.background_gradient(cmap='RdBu'))
        with col_r:
            st.write("### å‘é‡è´¡çŒ®å›¾")
            fig_l, ax = plt.subplots(figsize=(6, 6))
            ax.axhline(0, color='grey', linestyle='--')
            ax.axvline(0, color='grey', linestyle='--')
            for i, feat in enumerate(df_loadings.index):
                ax.arrow(0, 0, df_loadings.iloc[i, 0], df_loadings.iloc[i, 1], 
                         color='red', width=0.01, head_width=0.05)
                ax.text(df_loadings.iloc[i, 0]*1.2, df_loadings.iloc[i, 1]*1.2, feat, color='darkblue')
            ax.set_xlabel("PCA 1")
            ax.set_ylabel("PCA 2")
            st.pyplot(fig_l)
    else:
        st.warning("æ— æ³•è®¡ç®— PCAï¼Œå¯èƒ½ç¼ºå°‘æ•°å€¼åˆ—ã€‚")

# --- Tab 5: å¯Œé›†çƒ­å›¾ ---
with tab5:
    st.write("### ä¸“ä¸šç”Ÿç‰©å­¦æœ¯è¯­å¯Œé›†åº¦")
    
    BIO_DICT = {
        'Loc': ['mitochondrion', 'nucleus', 'membrane', 'cytoplasm', 'secreted'],
        'Func': ['kinase', 'transcription', 'transport', 'metabolism', 'immune'],
        'Struct': ['zinc', 'finger', 'domain', 'repeat']
    }
    
    keywords = [k for v in BIO_DICT.values() for k in v]
    
    if 'Cluster' in df_main.columns:
        clusters = sorted(df_main['Cluster'].unique())
        heatmap_data = []
        for k in keywords:
            row_data = []
            for c in clusters:
                sub = df_main[df_main['Cluster'] == c]
                if len(sub) > 0:
                    ratio = sub['cc_function'].str.contains(k, case=False).mean() * 100
                else:
                    ratio = 0
                row_data.append(ratio)
            heatmap_data.append(row_data)
            
        df_heatmap = pd.DataFrame(heatmap_data, index=keywords, columns=clusters)
        
        fig_h, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(df_heatmap, cmap='YlGnBu', annot=True, fmt=".1f", ax=ax)
        ax.set_title("Keyword Frequency by Cluster (%)")
        ax.set_xlabel("Cluster ID")
        st.pyplot(fig_h)
    else:
        st.warning("æ•°æ®ä¸­ç¼ºå°‘ Cluster åˆ—ï¼Œæ— æ³•ç»˜åˆ¶çƒ­å›¾ã€‚")

# åº•éƒ¨
st.markdown("---")
st.caption("BioGraph App v2.1 | Powered by Streamlit & UniProt")
