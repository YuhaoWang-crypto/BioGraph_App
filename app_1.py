import streamlit as st
import pandas as pd
import networkx as nx
import os
from pyvis.network import Network
import streamlit.components.v1 as components
import gdown
import itertools
from collections import Counter

# ==========================================
# âš™ï¸ 1. é¡µé¢é…ç½®ä¸åŸºç¡€è®¾ç½®
# ==========================================
st.set_page_config(page_title="BioGraph å…¨æ™¯åˆ†æå¹³å°", layout="wide", page_icon="ğŸ§¬")

# è·¯å¾„è®¾ç½®
DATA_FILE = "data/master_graph_data.csv"
CACHE_DIR = "checkpoints"
os.makedirs(CACHE_DIR, exist_ok=True)

# === ç¡¬ç¼–ç çš„åŠŸèƒ½æ¨¡å—å­—å…¸ (æ¥è‡ªä½ çš„ Colab) ===
FUNCTION_THEMES = {
    'ğŸ›¡ï¸ å…ç–«ç³»ç»Ÿ (Immune)': ['Immunoglobulin', 'Cytokine', 'MHC', 'IPR007110', 'Interferon', 'Inflammation', 'T-cell', 'B-cell'],
    'âš¡ ä»£è°¢ä¸èƒ½é‡ (Metabolism)': ['Mitochondrion', 'ATPase', 'Kinase', 'Glycolysis', 'Lipid', 'IPR000719', 'IPR004033'],
    'ğŸ§¬ åŸºå› è¡¨è¾¾ (Gene Reg)': ['Nucleus', 'Zinc Finger', 'Homeobox', 'transcription', 'Histone', 'Chromatin', 'RNA-binding'],
    'ğŸ—ï¸ ç»†èƒéª¨æ¶ (Cytoskeleton)': ['Actin', 'Tubulin', 'Kinesin', 'Microtubule', 'Myosin', 'Filament', 'Centrosome'],
    'ğŸ“¡ ä¿¡å·ä¼ å¯¼ (Signaling)': ['Receptor', 'Membrane', 'SH2', 'G-protein', 'Phosphatase', 'Growth factor', 'MAPK'],
    'ğŸ’€ ç»†èƒæ­»äº¡ (Cell Death)': ['Apoptosis', 'Caspase', 'Bcl-2', 'Death domain', 'Autophagy', 'Lysosome', 'Necrosis'],
    'ğŸ§  ç¥ç»ç³»ç»Ÿ (Neuro)': ['Synapse', 'Axon', 'Channel', 'Neurotransmitter', 'GABA', 'Glutamate'],
    'ğŸ§Š è‡ªå™¬ä¸é™è§£ (Autophagy)': ['Autophagy', 'Lysosome', 'Ubiquitin', 'Proteasome', 'LC3', 'SQSTM1', 'ATG'],
    'ğŸ”¥ ç¼ºæ°§ä¸åº”æ¿€ (Hypoxia/Stress)': ['Hypoxia', 'HIF', 'HSPA5', 'UPR', 'ER stress', 'Heat shock'],
    'ğŸ§¬ DNAæŸä¼¤ä¿®å¤ (DNA Repair)': ['BRCA', 'RAD51', 'ATM', 'ATR', 'Damage', 'Repair', 'Checkpoint']
}

# ==========================================
# ğŸ“¥ 2. æ•°æ®åŠ è½½æ ¸å¿ƒ
# ==========================================
@st.cache_resource
def load_graph_data():
    # ç¡®ä¿ data æ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs(os.path.dirname(DATA_FILE), exist_ok=True)

    # ä¸‹è½½é€»è¾‘
    if not os.path.exists(DATA_FILE) or os.path.getsize(DATA_FILE) < 1000:
        file_id = '1tM-n8EOVCPNLg9j9JfoIgg-SFYSML5XM'  # ä½ çš„ File ID
        url = f'https://drive.google.com/uc?id={file_id}'
        with st.spinner('æ­£åœ¨ä»äº‘ç«¯ä¸‹è½½æ•°æ®...'):
            gdown.download(url, DATA_FILE, quiet=False, fuzzy=True)

    # è¯»å–é€»è¾‘
    with st.spinner('æ­£åœ¨æ„å»ºå†…å­˜å›¾è°±...'):
        if not os.path.exists(DATA_FILE):
            return None, None
        
        try:
            df = pd.read_csv(DATA_FILE)
            # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœ CSV é‡Œæ²¡æœ‰ anno åˆ—ï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„
            if 'Source_Anno' not in df.columns: df['Source_Anno'] = ''
            if 'Target_Anno' not in df.columns: df['Target_Anno'] = ''
            # å…¼å®¹æ€§å¤„ç†ï¼šIDR åˆ—
            if 'Source_IDR' not in df.columns: df['Source_IDR'] = -1.0 # å‡è®¾
            
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
            os.remove(DATA_FILE)
            return None, None

        G = nx.Graph()
        for _, row in df.iterrows():
            s, t = row['Source'], row['Target']
            
            # è¯»å–è¾¹å±æ€§
            score = row.get('score_Swmed', 0.0)
            is_known = row.get('in_BioGRID', False)
            
            # å†™å…¥è¾¹
            G.add_edge(s, t, swmed=score, known=is_known, resistance=1.0/max(score, 0.001))
            
            # å†™å…¥èŠ‚ç‚¹å±æ€§ (å¦‚æœèŠ‚ç‚¹å·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œç®€å•èµ·è§è¿™é‡Œè¦†ç›–)
            # æ³¨æ„ï¼šCSV æ˜¯è¾¹åˆ—è¡¨ï¼ŒèŠ‚ç‚¹å±æ€§éœ€è¦å»é‡ã€‚è¿™é‡Œä¸ºäº†é€Ÿåº¦ï¼Œæ¯æ¬¡éƒ½å†™ä¸€éä¹Ÿæ²¡äº‹
            for node, prefix in [(s, 'Source'), (t, 'Target')]:
                G.add_node(node, 
                           loc=str(row.get(f'{prefix}_Loc', 'Unknown')),
                           dom=str(row.get(f'{prefix}_Domain', '')),
                           anno=str(row.get(f'{prefix}_Anno', '')),
                           # å°è¯•è¯»å– IDR (å¦‚æœä½ çš„ CSV åæ¥è¡¥å……äº†è¿™åˆ—)
                           idr=float(row.get(f'{prefix}_IDR', -1.0))
                )
        return G, df

G, master_df = load_graph_data()

if G is None:
    st.error("æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·åˆ·æ–°é¡µé¢ã€‚")
    st.stop()

ALL_GENES = sorted(list(G.nodes()))

# ==========================================
# ğŸ¨ 3. ä¾§è¾¹æ ä¸æ¨¡å—é€‰æ‹©
# ==========================================
st.sidebar.title("ğŸ§¬ BioGraph Pro")
module = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½æ¨¡å—:", [
    "ğŸ•µï¸â€â™‚ï¸ æ·±åº¦è›‹ç™½ä¾¦æ¢ (Detective)",
    "ğŸ“š GO/åŠŸèƒ½ æ™ºèƒ½æœç´¢ (GO Search)",
    "âš–ï¸ å…¨æ™¯åŒè½¨åˆ†æ (Panorama)",
    "ğŸ”€ æ¨¡å—ä¸²æ‰°æŒ–æ˜ (Crosstalk)",
    "ğŸ—ºï¸ å®šå‘è·¯å¾„æŒ–æ˜ (Pathfinder)",
    "â™Ÿï¸ æˆ˜ç•¥é˜»æ–­æ¨¡æ‹Ÿ (Blockade)",
    "ğŸ§ª ç»„å­¦å¹•åé»‘æ‰‹ (Omics Miner)",
    "ğŸ’§ é—å¤±çš„é­”æœ¯è´´ (IDR/LLPS)"
])

# ==========================================
# ğŸ•µï¸â€â™‚ï¸ æ¨¡å— 1: æ·±åº¦è›‹ç™½ä¾¦æ¢
# ==========================================
if module.startswith("ğŸ•µï¸â€â™‚ï¸"):
    st.header("ğŸ•µï¸â€â™‚ï¸ æ·±åº¦è›‹ç™½ä¾¦æ¢")
    col1, col2, col3 = st.columns([2, 1, 1])
    target = col1.selectbox("ç›®æ ‡è›‹ç™½:", ALL_GENES, index=ALL_GENES.index('TP53') if 'TP53' in ALL_GENES else 0)
    min_score = col2.slider("AI åˆ†æ•°é˜ˆå€¼:", 0.0, 1.0, 0.0)
    filter_loc = col3.text_input("ç­›é€‰å®šä½ (å¯é€‰):", placeholder="å¦‚ Nucleus")

    if st.button("å¼€å§‹ä¾¦æŸ¥"):
        props = G.nodes[target]
        st.info(f"**{target}** ä¿¡æ¯: ğŸ“ {props.get('loc')} | ğŸ§© {props.get('dom')[:50]}...")
        
        data = []
        for n in G.neighbors(target):
            edge = G[target][n]
            n_props = G.nodes[n]
            
            # ç­›é€‰
            if edge.get('swmed', 0) < min_score and not edge.get('known'): continue
            if filter_loc and filter_loc.lower() not in n_props.get('loc', '').lower(): continue
            
            data.append({
                "Partner": n,
                "Type": "âœ…å·²çŸ¥" if edge.get('known') else "ğŸ¤–é¢„æµ‹",
                "Score": edge.get('swmed', 0),
                "Location": n_props.get('loc', 'Unk'),
                "Annotation": n_props.get('anno', '')[:50] + "..."
            })
        
        df_res = pd.DataFrame(data).sort_values("Score", ascending=False)
        st.write(f"æ‰¾åˆ° {len(df_res)} ä¸ªä¼™ä¼´:")
        st.dataframe(df_res, use_container_width=True)

# ==========================================
# ğŸ“š æ¨¡å— 2: GO/åŠŸèƒ½ æ™ºèƒ½æœç´¢
# ==========================================
elif module.startswith("ğŸ“š"):
    st.header("ğŸ“š GO/åŠŸèƒ½ æ™ºèƒ½æœç´¢")
    st.markdown("é€šè¿‡åŸºå› æœ¬ä½“è®º (GO) æˆ–å…³é”®è¯æœç´¢å…·æœ‰ç‰¹å®šåŠŸèƒ½çš„è›‹ç™½é›†åˆã€‚")
    
    col1, col2 = st.columns([3, 1])
    keywords = col1.text_input("è¾“å…¥å…³é”®è¯ (é€—å·åˆ†éš”):", "autophagy, hypoxia")
    match_mode = col2.radio("åŒ¹é…æ¨¡å¼:", ["ä»»æ„åŒ¹é… (OR)", "å…¨éƒ¨åŒ¹é… (AND)"])
    
    if st.button("å…¨åº“æœç´¢"):
        kws = [k.strip().lower() for k in keywords.split(',') if k.strip()]
        if not kws: st.warning("è¯·è¾“å…¥å…³é”®è¯")
        else:
            hits = []
            for n, d in G.nodes(data=True):
                anno = str(d.get('anno', '')).lower()
                # åŒæ—¶ä¹Ÿæœåå­—
                name_match = any(kw in n.lower() for kw in kws)
                
                if match_mode.startswith("å…¨éƒ¨"):
                    is_match = all(kw in anno for kw in kws)
                else:
                    is_match = any(kw in anno for kw in kws) or name_match
                
                if is_match:
                    hits.append({
                        "Gene": n,
                        "Loc": d.get('loc'),
                        "Snippet": anno[:100] + "..."
                    })
            
            df_hits = pd.DataFrame(hits)
            st.success(f"ğŸ” æ‰¾åˆ° {len(df_hits)} ä¸ªç›¸å…³è›‹ç™½")
            if not df_hits.empty:
                st.dataframe(df_hits, use_container_width=True)

# ==========================================
# âš–ï¸ æ¨¡å— 3: å…¨æ™¯åŒè½¨åˆ†æ
# ==========================================
elif module.startswith("âš–ï¸"):
    st.header("âš–ï¸ å…¨æ™¯åŒè½¨åˆ†æ (Balanced View)")
    st.markdown("å¯¹æ¯” **å·²çŸ¥é€šè·¯ ** ä¸ **AI é¢„æµ‹ **ï¼Œå‘ç°æ¨¡å—é—´çš„æ½œåœ¨è”ç³»ã€‚")
    
    opts = list(FUNCTION_THEMES.keys())
    c1, c2 = st.columns(2)
    theme_a = c1.selectbox("æ¨¡å— A:", opts, index=0)
    theme_b = c2.selectbox("æ¨¡å— B:", opts, index=1)
    
    if st.button("è¿è¡Œå…¨æ™¯æ‰«æ"):
        if theme_a == theme_b:
            st.warning("è¯·é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„æ¨¡å—ã€‚")
        else:
            # 1. ç­›é€‰èŠ‚ç‚¹
            def get_nodes(theme):
                kws = FUNCTION_THEMES[theme]
                res = set()
                for n, d in G.nodes(data=True):
                    content = (str(d.get('loc')) + str(d.get('dom')) + str(d.get('anno'))).lower()
                    if any(k.lower() in content for k in kws): res.add(n)
                return res
            
            nodes_a = get_nodes(theme_a)
            nodes_b = get_nodes(theme_b)
            
            st.write(f"ğŸ”¹ æ¨¡å— A ({theme_a}): {len(nodes_a)} èŠ‚ç‚¹")
            st.write(f"ğŸ”¸ æ¨¡å— B ({theme_b}): {len(nodes_b)} èŠ‚ç‚¹")
            
            # 2. æ‰¾è¿æ¥
            edges = []
            for u in nodes_a:
                for v in nodes_b:
                    if G.has_edge(u, v):
                        e = G[u][v]
                        edges.append({
                            "Source (A)": u, "Target (B)": v,
                            "Type": "âœ…å·²çŸ¥" if e.get('known') else "ğŸš€é¢„æµ‹",
                            "Score": e.get('swmed', 0)
                        })
            
            df = pd.DataFrame(edges).sort_values("Score", ascending=False)
            
            tab1, tab2 = st.tabs(["âœ… å·²çŸ¥é€šè·¯ (Benchmark)", "ğŸš€ æ½œåœ¨å‘ç° (Discovery)"])
            with tab1:
                st.dataframe(df[df['Type'].str.contains("å·²çŸ¥")], use_container_width=True)
            with tab2:
                st.dataframe(df[df['Type'].str.contains("é¢„æµ‹")], use_container_width=True)

# ==========================================
# ğŸ”€ æ¨¡å— 4: æ¨¡å—ä¸²æ‰°æŒ–æ˜
# ==========================================
elif module.startswith("ğŸ”€"):
    st.header("ğŸ”€ åŠŸèƒ½æ¨¡å—ä¸²æ‰°æŒ–æ˜ (Crosstalk)")
    st.markdown("å¯»æ‰¾è¿æ¥ä¸¤ä¸ªåŠŸèƒ½æ¨¡å—çš„ **å…³é”®æ¡¥æ¢è›‹ç™½ (Bridge Proteins)**ã€‚")
    
    opts = list(FUNCTION_THEMES.keys())
    c1, c2 = st.columns(2)
    theme_a = c1.selectbox("æ¨¡å— A:", opts, index=2)
    theme_b = c2.selectbox("æ¨¡å— B:", opts, index=4)
    
    if st.button("å¯»æ‰¾æ¡¥æ¢"):
        # å¤ç”¨ç­›é€‰é€»è¾‘
        def get_nodes(theme):
            kws = FUNCTION_THEMES[theme]
            return {n for n, d in G.nodes(data=True) 
                    if any(k.lower() in (str(d.get('loc'))+str(d.get('dom'))+str(d.get('anno'))).lower() for k in kws)}
        
        na, nb = get_nodes(theme_a), get_nodes(theme_b)
        
        # å¯»æ‰¾æ—¢è¿æ¥Aåˆè¿æ¥Bçš„ä¸­é—´äºº
        bridges = {}
        for n in G.nodes():
            if n in na or n in nb: continue # æ’é™¤æ¨¡å—å†…éƒ¨äººå‘˜ï¼ˆå¯»æ‰¾å¤–éƒ¨æ¡¥æ¢ï¼‰
            
            neighbors = set(G.neighbors(n))
            links_a = len(neighbors.intersection(na))
            links_b = len(neighbors.intersection(nb))
            
            if links_a > 0 and links_b > 0:
                bridges[n] = links_a * links_b # ç®€å•çš„æ‰“åˆ†ï¼šè¿æ¥æ•°çš„ä¹˜ç§¯
        
        if bridges:
            sorted_bridges = sorted(bridges.items(), key=lambda x: x[1], reverse=True)[:20]
            data = [{"Bridge Protein": k, "Links to A": "Many", "Links to B": "Many", "Score": v, 
                     "Loc": G.nodes[k].get('loc')} for k, v in sorted_bridges]
            st.success(f"æ‰¾åˆ° {len(bridges)} ä¸ªæ½œåœ¨æ¡¥æ¢ï¼Œå±•ç¤º Top 20:")
            st.dataframe(pd.DataFrame(data))
        else:
            st.warning("æœªæ‰¾åˆ°æ˜æ˜¾çš„å¤–éƒ¨æ¡¥æ¢ã€‚")

# ==========================================
# ğŸ—ºï¸ æ¨¡å— 5: å®šå‘è·¯å¾„æŒ–æ˜
# ==========================================
elif module.startswith("ğŸ—ºï¸"):
    st.header("ğŸ—ºï¸ å®šå‘è·¯å¾„æŒ–æ˜æœº")
    c1, c2, c3 = st.columns(3)
    start = c1.selectbox("èµ·ç‚¹:", ALL_GENES, index=0)
    end = c2.selectbox("ç»ˆç‚¹:", ALL_GENES, index=1)
    via = c3.multiselect("å¿…ç»ç‚¹ (å¯é€‰):", ALL_GENES)
    
    if st.button("è§„åˆ’è·¯çº¿"):
        try:
            path = []
            if not via:
                path = nx.shortest_path(G, start, end, weight='resistance')
                cost = nx.shortest_path_length(G, start, end, weight='resistance')
            else:
                # ç®€å•å®ç°ï¼šç»è¿‡ç¬¬ä¸€ä¸ªå¿…ç»ç‚¹
                v = via[0]
                p1 = nx.shortest_path(G, start, v, weight='resistance')
                p2 = nx.shortest_path(G, v, end, weight='resistance')
                path = p1 + p2[1:]
                cost = "N/A"
            
            st.code(" -> ".join(path))
            st.caption(f"è·¯å¾„æ€»é˜»åŠ›: {cost}")
            
            # è¯¦æƒ…
            steps = []
            for i in range(len(path)-1):
                u, v = path[i], path[i+1]
                e = G[u][v]
                steps.append({"Step": f"{u}->{v}", "Type": "Known" if e.get('known') else "AI", "Score": e.get('swmed')})
            st.dataframe(pd.DataFrame(steps))
            
        except nx.NetworkXNoPath:
            st.error("æ— é€šè·¯")

# ==========================================
# â™Ÿï¸ æ¨¡å— 6: æˆ˜ç•¥é˜»æ–­æ¨¡æ‹Ÿ
# ==========================================
elif module.startswith("â™Ÿï¸"):
    st.header("â™Ÿï¸ æˆ˜ç•¥é˜»æ–­æ¨¡æ‹Ÿ")
    c1, c2 = st.columns(2)
    s = c1.selectbox("èµ·ç‚¹:", ALL_GENES, key='bk_s')
    e = c2.selectbox("ç»ˆç‚¹:", ALL_GENES, key='bk_e')
    
    if st.button("æ¨æ¼”ä»£å¿"):
        try:
            base_path = nx.shortest_path(G, s, e, weight='resistance')
            base_cost = nx.shortest_path_length(G, s, e, weight='resistance')
            
            res = []
            targets = base_path[1:-1]
            if not targets: st.warning("è·¯å¾„å¤ªçŸ­ï¼Œæ— ä¸­é—´é¶ç‚¹ã€‚")
            
            for t in targets:
                G_tmp = G.copy()
                G_tmp.remove_node(t)
                try:
                    new_cost = nx.shortest_path_length(G_tmp, s, e, weight='resistance')
                    impact = (new_cost - base_cost)/base_cost * 100
                    res.append({"Target": t, "Impact": impact, "New Cost": new_cost})
                except:
                    res.append({"Target": t, "Impact": 9999, "New Cost": "Inf"})
            
            st.dataframe(pd.DataFrame(res).sort_values("Impact", ascending=False).style.apply(
                lambda x: ['background-color: #ffcccc' if x['Impact'] > 1000 else '' for i in x], axis=1
            ))
        except:
            st.error("è®¡ç®—å‡ºé”™æˆ–æ— é€šè·¯")

# ==========================================
# ğŸ§ª æ¨¡å— 7: ç»„å­¦å¹•åé»‘æ‰‹
# ==========================================
elif module.startswith("ğŸ§ª"):
    st.header("ğŸ§ª ç»„å­¦æ•°æ®æŒ–æ˜æœº (Omics Miner)")
    st.markdown("è¾“å…¥ä¸€ç»„çœ‹ä¼¼ä¸ç›¸å…³çš„å·®å¼‚è›‹ç™½ï¼Œå¯»æ‰¾è¿æ¥å®ƒä»¬çš„**éšå½¢æ¢çº½ (Hidden Hubs)**ã€‚")
    
    default_list = "TP53, EGFR, BCL2, CDK1, MYC"
    user_input = st.text_area("è¾“å…¥åŸºå› åˆ—è¡¨ (é€—å·æˆ–æ¢è¡Œåˆ†éš”):", default_list)
    
    if st.button("æŒ–æ˜é»‘æ‰‹"):
        genes = [g.strip().upper() for g in user_input.replace('\n', ',').split(',') if g.strip()]
        valid = [g for g in genes if g in G]
        st.write(f"âœ… æœ‰æ•ˆè¯†åˆ«: {len(valid)} ä¸ªåŸºå› ")
        
        if len(valid) < 2:
            st.error("åŸºå› å¤ªå°‘ï¼Œæ— æ³•åˆ†æ")
        else:
            # å¯»æ‰¾éšå½¢æ¢çº½
            hubs = {}
            for n in G.nodes():
                if n in valid: continue
                neighbors = set(G.neighbors(n))
                overlap = len(neighbors.intersection(set(valid)))
                if overlap >= 2:
                    hubs[n] = overlap
            
            if hubs:
                top_hubs = sorted(hubs.items(), key=lambda x: x[1], reverse=True)[:10]
                df_hubs = pd.DataFrame(top_hubs, columns=["Hidden Hub", "Connected Targets"])
                st.success("ğŸ•µï¸â€â™‚ï¸ å‘ç°æ½œåœ¨çš„å¹•åè°ƒæ§è€…:")
                st.dataframe(df_hubs)
                
                # å¯è§†åŒ– Top 1
                top_hub = top_hubs[0][0]
                sub_nodes = valid + [top_hub]
                subG = G.subgraph(sub_nodes)
                
                net = Network(height="500px", width="100%", bgcolor="#222")
                for n in subG.nodes():
                    color = "#ff0000" if n == top_hub else "#00ff00"
                    net.add_node(n, label=n, color=color)
                for u, v in subG.edges():
                    net.add_edge(u, v, color="gray")
                
                path = "tmp_omics.html"
                net.save_graph(path)
                with open(path, 'r', encoding='utf-8') as f:
                    components.html(f.read(), height=520)

# ==========================================
# ğŸ’§ æ¨¡å— 8: é—å¤±çš„é­”æœ¯è´´ (IDR/LLPS)
# ==========================================
elif module.startswith("ğŸ’§"):
    st.header("ğŸ’§ é—å¤±çš„é­”æœ¯è´´ (Missing Velcro)")
    st.markdown("æŒ–æ˜ **é«˜ IDR (æ— åºåŒº)** é©±åŠ¨çš„ã€å¯èƒ½è¢«ä¼ ç»Ÿç»“æ„é¢„æµ‹é—æ¼çš„ç›¸åˆ†ç¦»äº’ä½œã€‚")
    
    tab1, tab2 = st.tabs(["ğŸ” å•è›‹ç™½åˆ†æ (éœ€ metapredict)", "ğŸ’ å…¨å±€æŒ–æ˜ (åŸºäºæ•°æ®)"])
    
    with tab1:
        g_in = st.text_input("è¾“å…¥åŸºå› å:", "FUS")
        if st.button("è®¡ç®—åºåˆ— IDR"):
            try:
                import metapredict as meta
                import requests
                # ç®€åŒ–ç‰ˆé€»è¾‘
                url = "https://rest.uniprot.org/uniprotkb/search"
                res = requests.get(url, params={'query': f"gene_exact:{g_in} AND reviewed:true", 'format': 'json'}).json()
                if res['results']:
                    seq = res['results'][0]['sequence']['value']
                    scores = meta.predict_disorder(seq)
                    frac = sum(1 for s in scores if s>0.5)/len(seq)
                    st.metric("IDR æ¯”ä¾‹", f"{frac:.2%}")
                    st.line_chart(scores)
                else:
                    st.error("æœªæ‰¾åˆ°åºåˆ—")
            except:
                st.warning("äº‘ç«¯ç¼ºå°‘ metapredict æˆ–ç½‘ç»œé—®é¢˜ã€‚")
                
    with tab2:
        if st.button("æ‰«ææ½œåœ¨æ¶²æ»´äº’ä½œ"):
            # æ‰«æå›¾è°±ä¸­ IDR > 0.4 çš„èŠ‚ç‚¹
            high_idr_nodes = []
            for n, d in G.nodes(data=True):
                # å°è¯•ä»èŠ‚ç‚¹å±æ€§è¯»å– idr (å¦‚æœä¹‹å‰å­˜è¿‡)
                idr = d.get('idr', -1)
                if idr > 0.4:
                    high_idr_nodes.append({'Gene': n, 'IDR': idr, 'Loc': d.get('loc')})
            
            if not high_idr_nodes:
                st.warning("å½“å‰å›¾è°±æ•°æ®ä¸­æœªåŒ…å«é¢„è®¡ç®—çš„ IDR ä¿¡æ¯ã€‚è¯·åœ¨ Colab ä¸­è¿è¡Œ 'æ‰¹é‡è®¡ç®—' å¹¶ä¿å­˜åˆ° CSVã€‚")
            else:
                st.write(f"å‘ç° {len(high_idr_nodes)} ä¸ªé«˜æ— åºè›‹ç™½ã€‚æ­£åœ¨ä¸¤ä¸¤é…å¯¹...")
                # ç®€å•çš„ä¸¤ä¸¤é…å¯¹é€»è¾‘ (å–å‰ 50 ä¸ªæ¼”ç¤º)
                cands = sorted(high_idr_nodes, key=lambda x:x['IDR'], reverse=True)[:50]
                pairs = []
                for i in range(len(cands)):
                    for j in range(i+1, len(cands)):
                        u, v = cands[i], cands[j]
                        # å¦‚æœæ²¡æœ‰å·²çŸ¥äº’ä½œï¼Œä¸” AI åˆ†æ•°ä½ï¼Œä½†éƒ½æœ‰é«˜ IDR -> å¯èƒ½æ˜¯ LLPS
                        if not G.has_edge(u['Gene'], v['Gene']):
                            pairs.append({
                                "Protein A": u['Gene'], "IDR A": u['IDR'],
                                "Protein B": v['Gene'], "IDR B": v['IDR'],
                                "Prediction": "ğŸ’§ LLPS Potential"
                            })
                
                if pairs:
                    st.dataframe(pd.DataFrame(pairs))
                else:
                    st.info("æœªå‘ç°æ˜¾è‘—é…å¯¹ã€‚")
